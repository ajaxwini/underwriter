{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "# # Importing Module\n",
    "# - pandas for formatting or provides table\n",
    "# - seabourn is wrapper over matplotlib\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import csv\n",
    "from collections import defaultdict\n",
    "\n",
    "import re\n",
    "from datetime import datetime\n",
    "#get_ipython().magic('matplotlib inline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[4]:\n",
    "gender = r'(\\b[Mm]ale)|(\\b[Ff]emale)|(\\bFEMALE)|(\\bMALE)'\n",
    "#gender = 'Female'or'Male'or'female'or'male'or'FEMALE'or'MALE'\n",
    "\n",
    "Date = r'(([A-Z0-9][A-Z0-9]?[/])?[A-Z0-9][A-Z0-9]?[/][A-Z0-9][A-Z0-9][A-Z0-9]?[A-Z0-9]?)|([A-Za-z][A-Za-z][A-Za-z]\\s..?[,]\\s....)'\n",
    "\n",
    "DOB  = r'DOB|[Dd][aA][tT][eE]\\s[oO][fF]\\s[Bb][iI][rR][tT][hH]'\n",
    "\n",
    "year=r'\\b(19|20)\\d{2}\\b'\n",
    "\n",
    "product_type = r'(\\b[Pp]roduct\\s[Tt]ype):\\s?.*'\n",
    "\n",
    "faceamount = r'(\\b[Ff]ace\\s?[Aa]mount:?\\s?.*)'\n",
    "\n",
    "term = r'[Tt][eE][rR][mM]'\n",
    "term_amount=r'[0-9]*'\n",
    "\n",
    "weight = r'((?:[kK][gG]\\.?)[ ]*\\d+(?:[.,]\\d+)?|\\d+(?:[.,]\\d+)?[ ]*(?:[kK][gG]\\.?))'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'face updated\\nhad bypass in 2010. \\ntakes following medications:\\n1. metoprolol (blood pressure) - diagnosed 2014 - takes 25 mg daily \\n2. levothyroxine (thyroid) - diagnosed 2016 - takes 25 mg daily \\n'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"before_after.csv\",encoding= \"utf-8\")\n",
    "df[\"Before\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords,wordnet as wn\n",
    "from nltk.tokenize import wordpunct_tokenize,sent_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import re\n",
    "\n",
    "\n",
    "# In[18]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rem_punt(doc):\n",
    "    ans = re.sub('\"|\\\\n|\\(|\\)|,|\\.|[$!--+@#:]',' ',doc)\n",
    "    ans = re.sub(' +',' ',ans)\n",
    "    ans = ans.lower()\n",
    "    return ans\n",
    "\n",
    "stop_word = set(stopwords.words('english'))\n",
    "\n",
    "def tokenize(document): \n",
    "    lemmy = []\n",
    "    for sent in sent_tokenize(document):\n",
    "        for token, tag in pos_tag(wordpunct_tokenize(sent)):\n",
    "            #print(token,tag)\n",
    "            if token in stop_word:\n",
    "                 continue\n",
    "            lemma = lemmatize(token, tag)\n",
    "            lemmy.append(lemma)\n",
    "    return lemmy\n",
    "\n",
    "def lemmatize(token, tag):\n",
    "    tag = {\n",
    "          'N': wn.NOUN,\n",
    "          'V': wn.VERB,\n",
    "          'R': wn.ADV,\n",
    "          'J': wn.ADJ\n",
    "    }.get(tag[0], wn.NOUN)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return lemmatizer.lemmatize(token, tag)\n",
    "\n",
    "def regex(document):\n",
    "    \n",
    "    values = []\n",
    "    #values.append('Product type')\n",
    "    v = re.search(product_type,document, re.I | re.U)\n",
    "    if v:\n",
    "        values.append(v.group(0))\n",
    "    else:\n",
    "        values.append('-1')\n",
    "        \n",
    "    v = re.search(faceamount,document, re.I | re.U)\n",
    "    w = re.search(term_amount, document, re.I | re.U)\n",
    "    #values.append('Face Amount')\n",
    "    if v:\n",
    "        values.append(v.group(0))\n",
    "    elif(re.search(w and term, document, re.I | re.U)):\n",
    "        values.append(w.group(0))\n",
    "    else:\n",
    "        values.append('-1')\n",
    "        \n",
    "    v = re.search(gender,document, re.I | re.U)\n",
    "    #values.append('Gender')\n",
    "    if v:\n",
    "        values.append(v.group(0))\n",
    "    else:   \n",
    "        values.append('-1')\n",
    "        \n",
    "    v = re.search(year,document, re.I | re.U)\n",
    "    u = re.search(DOB,document, re.I | re.U)\n",
    "    currentYear = datetime.now().year\n",
    "    #values.append('Age')\n",
    "    if v and u:\n",
    "        values.append(currentYear-(int)(v.group(0)))\n",
    "    else:   \n",
    "        values.append('-1')\n",
    "        \n",
    "    v = re.search(weight,document, re.I | re.U)\n",
    "    #values.append('Gender')\n",
    "    if v:\n",
    "        values.append(v.group(0))\n",
    "    else:   \n",
    "        values.append('-1')\n",
    "         \n",
    "        \n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['RmNoise'] = df['Before'].apply(rem_punt)\n",
    "\n",
    "df['Lemmitize'] = df['RmNoise'].apply(tokenize)\n",
    "\n",
    "df['Regex'] = df['Before'].apply(regex)\n",
    "\n",
    "df.to_csv('Script2data.csv',index=False, encoding = \"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[25]:\n",
    "\n",
    "df = pd.read_csv('Script2data.csv')\n",
    "\n",
    "\n",
    "# # Statistical Modeling \n",
    "\n",
    "# In[26]:\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Normalizer,LabelEncoder\n",
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "\n",
    "\n",
    "# In[28]:\n",
    "\n",
    "X = df['Lemmitize']\n",
    "y = df['Offer']\n",
    "#lab_y = LabelEncoder()\n",
    "#y = lab_y.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    A\n",
       "1    B\n",
       "2    A\n",
       "3    B\n",
       "Name: Offer, dtype: object"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[29]:\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y)\n",
    "\n",
    "\n",
    "# In[30]:\n",
    "\n",
    "vect = TfidfVectorizer(max_df=1.0, max_features=15000, min_df=0.001, use_idf=True , ngram_range=(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from xgboost.sklearn import XGBClassifier\n",
    "#model = XGBClassifier(nthread=4,n_estimators=1000)\n",
    "\n",
    "\n",
    "# # Navie Bayes\n",
    "\n",
    "# In[23]:\n",
    "\n",
    "#from sklearn.naive_bayes import GaussianNB,MultinomialNB\n",
    "#model = GaussianNB()\n",
    "\n",
    "\n",
    "# # ExtraTree Classifier\n",
    "\n",
    "# In[24]:\n",
    "\n",
    "#from sklearn.ensemble import ExtraTreesClassifier,RandomForestClassifier\n",
    "#model = RandomForestClassifier(n_estimators=600,n_jobs=-1)\n",
    "\n",
    "\n",
    "# # SVM Classifier\n",
    "# \n",
    "\n",
    "# In[25]:\n",
    "\n",
    "#from sklearn.svm import SVC\n",
    "#model = SVC()\n",
    "\n",
    "\n",
    "# # Logistic Regression \n",
    "\n",
    "# In[26]:\n",
    "\n",
    "#from sklearn.linear_model import LinearRegression,SGDClassifier,LogisticRegression\n",
    "#model = LogisticRegression()\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB,MultinomialNB\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier,RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LinearRegression,SGDClassifier,LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/scipy/sparse/compressed.py:130: VisibleDeprecationWarning: `rank` is deprecated; use the `ndim` attribute or function instead. To find the rank of a matrix see `numpy.linalg.matrix_rank`.\n",
      "  if np.rank(self.data) != 1 or np.rank(self.indices) != 1 or np.rank(self.indptr) != 1:\n",
      "/usr/lib/python3/dist-packages/scipy/sparse/coo.py:200: VisibleDeprecationWarning: `rank` is deprecated; use the `ndim` attribute or function instead. To find the rank of a matrix see `numpy.linalg.matrix_rank`.\n",
      "  if np.rank(self.data) != 1 or np.rank(self.row) != 1 or np.rank(self.col) != 1:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "=====Accuracy Score  100.00 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/scipy/sparse/compressed.py:130: VisibleDeprecationWarning: `rank` is deprecated; use the `ndim` attribute or function instead. To find the rank of a matrix see `numpy.linalg.matrix_rank`.\n",
      "  if np.rank(self.data) != 1 or np.rank(self.indices) != 1 or np.rank(self.indptr) != 1:\n",
      "/usr/local/lib/python3.4/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier(nthread=4,n_estimators=1000)\n",
    "clf = make_pipeline(vect,model)\n",
    "\n",
    "clf.fit(X_train,y_train)\n",
    "pd = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, pd)\n",
    "print(accuracy)\n",
    "print (\"=====Accuracy Score \", \"{0:.2f}\".format(metrics.accuracy_score(y_test, pd)*100), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/scipy/sparse/compressed.py:130: VisibleDeprecationWarning: `rank` is deprecated; use the `ndim` attribute or function instead. To find the rank of a matrix see `numpy.linalg.matrix_rank`.\n",
      "  if np.rank(self.data) != 1 or np.rank(self.indices) != 1 or np.rank(self.indptr) != 1:\n",
      "/usr/lib/python3/dist-packages/scipy/sparse/coo.py:200: VisibleDeprecationWarning: `rank` is deprecated; use the `ndim` attribute or function instead. To find the rank of a matrix see `numpy.linalg.matrix_rank`.\n",
      "  if np.rank(self.data) != 1 or np.rank(self.row) != 1 or np.rank(self.col) != 1:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "A sparse matrix was passed, but dense data is required. Use X.toarray() to convert to a dense numpy array.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-89-18123b407089>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvect\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mpd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \"\"\"\n\u001b[0;32m--> 183\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m         return self._partial_fit(X, y, np.unique(y), _refit=True,\n\u001b[1;32m    185\u001b[0m                                  sample_weight=sample_weight)\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    571\u001b[0m     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n\u001b[1;32m    572\u001b[0m                     \u001b[0mensure_2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m                     ensure_min_features, warn_on_dtype, estimator)\n\u001b[0m\u001b[1;32m    574\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    429\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m         array = _ensure_sparse_format(array, accept_sparse, dtype, copy,\n\u001b[0;32m--> 431\u001b[0;31m                                       force_all_finite)\n\u001b[0m\u001b[1;32m    432\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_ensure_sparse_format\u001b[0;34m(spmatrix, accept_sparse, dtype, copy, force_all_finite)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maccept_sparse\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m         raise TypeError('A sparse matrix was passed, but dense '\n\u001b[0m\u001b[1;32m    276\u001b[0m                         \u001b[0;34m'data is required. Use X.toarray() to '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m                         'convert to a dense numpy array.')\n",
      "\u001b[0;31mTypeError\u001b[0m: A sparse matrix was passed, but dense data is required. Use X.toarray() to convert to a dense numpy array."
     ]
    }
   ],
   "source": [
    "model = GaussianNB()\n",
    "clf = make_pipeline(vect,model)\n",
    "\n",
    "clf.fit(X_train,y_train)\n",
    "pd = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, pd)\n",
    "print(accuracy)\n",
    "print (\"=====Accuracy Score \", \"{0:.2f}\".format(metrics.accuracy_score(y_test, pd)*100), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/scipy/sparse/compressed.py:130: VisibleDeprecationWarning: `rank` is deprecated; use the `ndim` attribute or function instead. To find the rank of a matrix see `numpy.linalg.matrix_rank`.\n",
      "  if np.rank(self.data) != 1 or np.rank(self.indices) != 1 or np.rank(self.indptr) != 1:\n",
      "/usr/lib/python3/dist-packages/scipy/sparse/coo.py:200: VisibleDeprecationWarning: `rank` is deprecated; use the `ndim` attribute or function instead. To find the rank of a matrix see `numpy.linalg.matrix_rank`.\n",
      "  if np.rank(self.data) != 1 or np.rank(self.row) != 1 or np.rank(self.col) != 1:\n",
      "/usr/lib/python3/dist-packages/scipy/sparse/compressed.py:130: VisibleDeprecationWarning: `rank` is deprecated; use the `ndim` attribute or function instead. To find the rank of a matrix see `numpy.linalg.matrix_rank`.\n",
      "  if np.rank(self.data) != 1 or np.rank(self.indices) != 1 or np.rank(self.indptr) != 1:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "=====Accuracy Score  100.00 %\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=600,n_jobs=-1)\n",
    "clf = make_pipeline(vect,model)\n",
    "\n",
    "clf.fit(X_train,y_train)\n",
    "pd = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, pd)\n",
    "print(accuracy)\n",
    "print (\"=====Accuracy Score \", \"{0:.2f}\".format(metrics.accuracy_score(y_test, pd)*100), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "=====Accuracy Score  0.00 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/scipy/sparse/compressed.py:130: VisibleDeprecationWarning: `rank` is deprecated; use the `ndim` attribute or function instead. To find the rank of a matrix see `numpy.linalg.matrix_rank`.\n",
      "  if np.rank(self.data) != 1 or np.rank(self.indices) != 1 or np.rank(self.indptr) != 1:\n",
      "/usr/lib/python3/dist-packages/scipy/sparse/coo.py:200: VisibleDeprecationWarning: `rank` is deprecated; use the `ndim` attribute or function instead. To find the rank of a matrix see `numpy.linalg.matrix_rank`.\n",
      "  if np.rank(self.data) != 1 or np.rank(self.row) != 1 or np.rank(self.col) != 1:\n",
      "/usr/lib/python3/dist-packages/scipy/sparse/compressed.py:119: UserWarning: indptr array has non-integer dtype (float64)\n",
      "  % self.indptr.dtype.name)\n"
     ]
    }
   ],
   "source": [
    "model = SVC()\n",
    "clf = make_pipeline(vect,model)\n",
    "\n",
    "clf.fit(X_train,y_train)\n",
    "pd = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, pd)\n",
    "print(accuracy)\n",
    "print (\"=====Accuracy Score \", \"{0:.2f}\".format(metrics.accuracy_score(y_test, pd)*100), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "=====Accuracy Score  100.00 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/scipy/sparse/compressed.py:130: VisibleDeprecationWarning: `rank` is deprecated; use the `ndim` attribute or function instead. To find the rank of a matrix see `numpy.linalg.matrix_rank`.\n",
      "  if np.rank(self.data) != 1 or np.rank(self.indices) != 1 or np.rank(self.indptr) != 1:\n",
      "/usr/lib/python3/dist-packages/scipy/sparse/coo.py:200: VisibleDeprecationWarning: `rank` is deprecated; use the `ndim` attribute or function instead. To find the rank of a matrix see `numpy.linalg.matrix_rank`.\n",
      "  if np.rank(self.data) != 1 or np.rank(self.row) != 1 or np.rank(self.col) != 1:\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "clf = make_pipeline(vect,model)\n",
    "\n",
    "clf.fit(X_train,y_train)\n",
    "pd = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, pd)\n",
    "print(accuracy)\n",
    "print (\"=====Accuracy Score \", \"{0:.2f}\".format(metrics.accuracy_score(y_test, pd)*100), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/scipy/sparse/compressed.py:130: VisibleDeprecationWarning: `rank` is deprecated; use the `ndim` attribute or function instead. To find the rank of a matrix see `numpy.linalg.matrix_rank`.\n",
      "  if np.rank(self.data) != 1 or np.rank(self.indices) != 1 or np.rank(self.indptr) != 1:\n",
      "/usr/lib/python3/dist-packages/scipy/sparse/coo.py:200: VisibleDeprecationWarning: `rank` is deprecated; use the `ndim` attribute or function instead. To find the rank of a matrix see `numpy.linalg.matrix_rank`.\n",
      "  if np.rank(self.data) != 1 or np.rank(self.row) != 1 or np.rank(self.col) != 1:\n",
      "/usr/lib/python3/dist-packages/scipy/sparse/compressed.py:130: VisibleDeprecationWarning: `rank` is deprecated; use the `ndim` attribute or function instead. To find the rank of a matrix see `numpy.linalg.matrix_rank`.\n",
      "  if np.rank(self.data) != 1 or np.rank(self.indices) != 1 or np.rank(self.indptr) != 1:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# # Model Fitting\n",
    "\n",
    "#t0 = time()\n",
    "\n",
    "# In[33]:\n",
    "\n",
    "#clf = make_pipeline(vect,model)\n",
    "\n",
    "\n",
    "# In[34]:\n",
    "\n",
    "#clf.fit(X_train,y_train)\n",
    "\n",
    "#print (\"training time:\", round(time()-t0, 3), \"s\")\n",
    "#t1 = time()\n",
    "\n",
    "# In[40]:\n",
    "\n",
    "#pd = clf.predict(X_test)\n",
    "#print (\"prediction time:\", round(time()-t1, 3), \"s\")\n",
    "\n",
    "#accuracy = accuracy_score(y_test, pd)\n",
    "#print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['A'], dtype=object)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    ['face', 'update', 'bypass', '2010', 'take', '...\n",
       "Name: Lemmitize, dtype: object"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
